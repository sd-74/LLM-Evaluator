{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textattack\n",
      "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting bert-score>=0.3.5 (from textattack)\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting editdistance (from textattack)\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting flair (from textattack)\n",
      "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (3.13.1)\n",
      "Collecting language-tool-python (from textattack)\n",
      "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lemminflect (from textattack)\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: lru-dict in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (1.3.0)\n",
      "Requirement already satisfied: datasets>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (2.19.2)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (1.10.0)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (2.2.0)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (4.38.0)\n",
      "Collecting terminaltables (from textattack)\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (4.66.1)\n",
      "Collecting word2number (from textattack)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting num2words (from textattack)\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: more-itertools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from textattack) (9.1.0)\n",
      "Collecting pinyin>=0.4.0 (from textattack)\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba (from textattack)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting OpenHowNet (from textattack)\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (3.8.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score>=0.3.5->textattack) (21.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.4.0->textattack) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (0.25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets>=2.4.0->textattack) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->textattack) (2022.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=4.30.0->textattack) (0.4.5)\n",
      "Collecting boto3>=1.20.27 (from flair->textattack)\n",
      "  Downloading boto3-1.35.21-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair->textattack)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
      "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting gdown>=4.4.0 (from flair->textattack)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair->textattack) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair->textattack) (4.9.2)\n",
      "Collecting mpld3>=0.3 (from flair->textattack)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair->textattack)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair->textattack) (1.3.2)\n",
      "Collecting segtok>=1.5.11 (from flair->textattack)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flair->textattack) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
      "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting semver<4.0.0,>=3.0.0 (from flair->textattack)\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from language-tool-python->textattack) (23.3.1)\n",
      "Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from language-tool-python->textattack) (0.38.4)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->textattack) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->textattack) (1.3.2)\n",
      "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anytree (from OpenHowNet->textattack)\n",
      "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from OpenHowNet->textattack) (66.0.0)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting botocore<1.36.0,>=1.35.21 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading botocore-1.35.21-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair->textattack)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy>=6.1.0->flair->textattack)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gdown>=4.4.0->flair->textattack) (4.11.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score>=0.3.5->textattack) (2022.12.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.2.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (4.24.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (0.25.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.3.2.post1)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (5.9.4)\n",
      "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
      "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading boto3-1.35.21-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.35.21-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: pinyin, jieba, word2number, docopt, pptree, sqlitedict, wikipedia-api, intervaltree\n",
      "  Building wheel for pinyin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=3c2175c1cabcdb6cae76bf12fedb41d40c0b287ab160f236d41a22e8ebd30d77\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=66e705cc8cde82f004fac139f6854271e9e387ff7a0fa358ed431a1d404d3eb9\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=fdca027b5e2437fc570508905db562f02ad0886626d231a56ccfc40535475cd5\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=1dba67fb1a8942a3c3bc0a30dbd2d270a798e280c86563a0343d4dfb8e52e758\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=71fd590bfcae3de19c572eb613e4eac533ee3cea84dc9e141681d512155ea83e\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=57eac637d075ce117afcac49f63fac4d81ce6d6527d1587b9b006dbf94a76af7\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=4350cd9756933b0c279d4dd50a97cbef78de0b9bea847a0b1b59fe2cb0161a7b\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=72f0b43cbf6e379b71e9d5595bdd8532c9f6f0c8255c1dff80c4c41710457e9d\n",
      "  Stored in directory: /Users/sumanthkalluru/Library/Caches/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "Successfully built pinyin jieba word2number docopt pptree sqlitedict wikipedia-api intervaltree\n",
      "Installing collected packages: word2number, wcwidth, sqlitedict, pptree, pinyin, jieba, docopt, terminaltables, semver, segtok, num2words, lemminflect, jsonlines, jmespath, intervaltree, ftfy, editdistance, deprecated, conllu, anytree, wikipedia-api, OpenHowNet, language-tool-python, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, gdown, boto3, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "Successfully installed OpenHowNet-2.0 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 boto3-1.35.21 botocore-1.35.21 conllu-4.5.3 deprecated-1.2.14 docopt-0.6.2 editdistance-0.8.1 flair-0.14.0 ftfy-6.2.3 gdown-5.2.0 intervaltree-3.1.0 jieba-0.42.1 jmespath-1.0.1 jsonlines-4.0.0 language-tool-python-2.8.1 lemminflect-0.2.3 mpld3-0.5.10 num2words-0.5.13 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.2 segtok-1.5.11 semver-3.0.2 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.10 transformer-smaller-training-vocab-0.4.0 wcwidth-0.2.13 wikipedia-api-0.7.1 word2number-1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textattack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Updating TextAttack package dependencies.\n",
      "textattack: Downloading NLTK required packages.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sumanthkalluru/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import promptbench as pb\n",
    "from promptbench.models import LLMModel\n",
    "from promptbench.prompt_attack import Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['textbugger', 'deepwordbug', 'textfooler', 'bertattack', 'checklist', 'stresstest', 'semantic']\n"
     ]
    }
   ],
   "source": [
    "model_t5 = LLMModel(model='google/flan-t5-large', device = 'cpu', temperature=0.7, do_sample=True)\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = pb.DatasetLoader.load_dataset(\"sst2\")\n",
    "\n",
    "# try part of the dataset\n",
    "dataset = dataset[:10]\n",
    "\n",
    "# create prompt\n",
    "prompt = \"As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \\nQuestion: {content}\\nAnswer:\"\n",
    "\n",
    "# define the projection function required by the output process\n",
    "def proj_func(pred):\n",
    "    mapping = {\n",
    "        \"positive\": 1,\n",
    "        \"negative\": 0\n",
    "    }\n",
    "    return mapping.get(pred, -1)\n",
    "\n",
    "# define the evaluation function required by the attack\n",
    "# if the prompt does not require any dataset, for example, \"write a poem\", you still need to include the dataset parameter\n",
    "def eval_func(prompt, dataset, model):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for d in dataset:\n",
    "        input_text = pb.InputProcess.basic_format(prompt, d)\n",
    "        raw_output = model(input_text)\n",
    "\n",
    "        output = pb.OutputProcess.cls(raw_output, proj_func)\n",
    "        preds.append(output)\n",
    "\n",
    "        labels.append(d[\"label\"])\n",
    "    \n",
    "    return pb.Eval.compute_cls_accuracy(preds, labels)\n",
    "    \n",
    "# define the unmodifiable words in the prompt\n",
    "# for example, the labels \"positive\" and \"negative\" are unmodifiable, and \"content\" is modifiable because it is a placeholder\n",
    "# if your labels are enclosed with '', you need to add \\' to the unmodifiable words (due to one feature of textattack)\n",
    "unmodifiable_words = [\"positive\\'\", \"negative\\'\", \"content\"]\n",
    "\n",
    "# print all supported attacks\n",
    "print(Attack.attack_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These words (if they appear in the prompt) are not allowed to be attacked:\n",
      "[\"positive'\", \"negative'\", 'content']\n",
      "--------------------------------------------------\n",
      "Current prompt is:  As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \n",
      "Question: {content}\n",
      "Answer:\n",
      "Current accuracy is:  1.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "Modifiable words:  ['As', 'a', 'sentiment', 'classifier', 'determine', 'whether', 'the', 'following', 'text', 'is', 'or', 'Please', 'classify', 'Question', 'Answer']\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "Current prompt is:  As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \n",
      "Question: {content}\n",
      "Answer  and false is not true :\n",
      "Current accuracy is:  1.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "Current prompt is:  As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \n",
      "Question: {content}\n",
      "Answer  and true is true  and true is true  and true is true  and true is true  and true is true :\n",
      "Current accuracy is:  1.0\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "Current prompt is:  As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \n",
      "Question: {content}\n",
      "Answer  and true is true :\n",
      "Current accuracy is:  1.0\n",
      "--------------------------------------------------\n",
      "\n",
      "{'original prompt': \"As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \\nQuestion: {content}\\nAnswer:\", 'original score': 1.0, 'attacked prompt': \"As a sentiment classifier, determine whether the following text is 'positive' or 'negative'. Please classify: \\nQuestion: {content}\\nAnswer  and false is not true :\", 'attacked score': 1.0, 'PDR': 0.0}\n"
     ]
    }
   ],
   "source": [
    "attack = Attack(model_t5, \"stresstest\", dataset, prompt, eval_func, unmodifiable_words, verbose=True)\n",
    "\n",
    "# print attack result\n",
    "print(attack.attack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
